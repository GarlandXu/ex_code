{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e190c113-7365-461e-b6a7-95d5b8251bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dba17d-ba5f-41f3-8e6b-8b9ba4b78c4d",
   "metadata": {},
   "source": [
    "2.1 CVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72ff4f68-14ce-462b-8b3d-8d1faf68c768",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, input_dim, ff_dim=256, dropout=0.1):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, ff_dim)\n",
    "        self.fc2 = nn.Linear(ff_dim, input_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim=3, hidden_dim=128, latent_dim=64, num_conditions=2, emb_dim=16, num_heads=4, ff_dim=256, dropout=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_conditions, emb_dim)\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim=2*hidden_dim, num_heads=num_heads, batch_first=True, dropout=dropout)\n",
    "        self.norm1 = nn.LayerNorm(2*hidden_dim)\n",
    "        self.norm2 = nn.LayerNorm(2*hidden_dim)\n",
    "        self.ff = FeedForward(input_dim=2*hidden_dim, ff_dim=ff_dim, dropout=dropout)\n",
    "        self.fc_inter_1 = nn.Linear(2*hidden_dim + emb_dim, 2*hidden_dim + emb_dim)\n",
    "        self.fc_inter_2 = nn.Linear(2*hidden_dim + emb_dim, 2*hidden_dim + emb_dim)\n",
    "        self.mu_layer = nn.Linear(2*hidden_dim + emb_dim, latent_dim)\n",
    "        self.logvar_layer = nn.Linear(2*hidden_dim + emb_dim, latent_dim)\n",
    "\n",
    "    def forward(self, x, c, start_point, end_point):\n",
    "        B,T,_ = x.size()\n",
    "        c_embed = self.embedding(c)\n",
    "        h_seq, _ = self.lstm(x)\n",
    "        attn_output, _ = self.multihead_attn(h_seq, h_seq, h_seq)\n",
    "        h_seq = self.norm1(h_seq + attn_output)\n",
    "        ff_output = self.ff(h_seq)\n",
    "        h_seq = self.norm2(h_seq + ff_output)\n",
    "        global_feat = h_seq.mean(dim=1)\n",
    "        h_cat = torch.cat([global_feat, c_embed], dim=-1)\n",
    "        inter = F.relu(self.fc_inter_1(h_cat))\n",
    "        inter = F.relu(self.fc_inter_2(inter))\n",
    "        mu = self.mu_layer(h_cat)\n",
    "        logvar = self.logvar_layer(h_cat)\n",
    "        return mu, logvar\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim=64, num_conditions=2, emb_dim=16, hidden_dim=256, seq_len=500, input_dim=3):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_conditions, emb_dim)\n",
    "        self.seq_len = seq_len\n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        cond_dim = latent_dim + emb_dim + 6\n",
    "        self.fc_cond = nn.Sequential(\n",
    "            nn.Linear(cond_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        self.time_embeddings = nn.Parameter(torch.randn(seq_len, hidden_dim))\n",
    "\n",
    "    \n",
    "        self.fc_out = nn.Sequential(\n",
    "            nn.Linear(hidden_dim*2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "\n",
    "        self.fc_start = nn.Sequential(\n",
    "            nn.Linear(hidden_dim*2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "\n",
    "        self.fc_end = nn.Sequential(\n",
    "            nn.Linear(hidden_dim*2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, z, c, start_point, end_point, seq_len=500):\n",
    "        B = z.size(0)\n",
    "        c_embed = self.embedding(c)\n",
    "        cond = torch.cat([z, c_embed, start_point, end_point], dim=-1)\n",
    "        g = self.fc_cond(cond)\n",
    "        g_expanded = g.unsqueeze(1).expand(B, self.seq_len, g.size(-1))\n",
    "        t_embed = self.time_embeddings.unsqueeze(0).expand(B, self.seq_len, -1)\n",
    "        gt_cat = torch.cat([g_expanded, t_embed], dim=-1)\n",
    "\n",
    "       \n",
    "        out_all = self.fc_out(gt_cat)  # [B,T,3]\n",
    "        \n",
    "       \n",
    "        start_out = self.fc_start(gt_cat[:,0,:])  # [B,3]\n",
    "        end_out = self.fc_end(gt_cat[:,-1,:])     # [B,3]\n",
    "\n",
    "      \n",
    "        out_all[:,0,:] = start_out\n",
    "        out_all[:,-1,:] = end_out\n",
    "        \n",
    "        return out_all\n",
    "\n",
    "\n",
    "class CVAE(nn.Module):\n",
    "    def __init__(self, input_dim=3, hidden_dim=256, latent_dim=64, num_conditions=2, emb_dim=16, num_heads=4):\n",
    "        super(CVAE, self).__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dim, latent_dim, num_conditions, emb_dim, num_heads)\n",
    "        self.decoder = Decoder(latent_dim, num_conditions, emb_dim, hidden_dim, seq_len=500, input_dim=3)\n",
    "\n",
    "    def forward(self, x, c, start_point, end_point):\n",
    "        mu, logvar = self.encoder(x, c, start_point, end_point)\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps * std\n",
    "        recon = self.decoder(z, c, start_point, end_point, seq_len=x.size(1))\n",
    "        return recon, mu, logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffc938c-b4be-412b-b9ba-6d32e7f8ea4c",
   "metadata": {},
   "source": [
    "2.3 loss fcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2216f4e-6b41-48e2-83c1-8febc2c6592a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loss_function(recon_x, x, mu, logvar, start_point, end_point, lambda_factor=2, alpha=0.5):\n",
    "   \n",
    "    mse_loss = F.mse_loss(recon_x, x, reduction='mean')\n",
    "    kld_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    start_loss = F.mse_loss(recon_x[:,0,:], start_point, reduction='mean')\n",
    "    end_loss = F.mse_loss(recon_x[:,-1,:], end_point, reduction='mean')\n",
    "    \n",
    "    \n",
    "    l1_loss = F.l1_loss(recon_x, x, reduction='mean')\n",
    "    start_l1 = F.l1_loss(recon_x[:,0,:], start_point, reduction='mean')\n",
    "    end_l1 = F.l1_loss(recon_x[:,-1,:], end_point, reduction='mean')\n",
    "    \n",
    "    \n",
    "    combined_recon = mse_loss + alpha * l1_loss\n",
    "    recon_loss = combined_recon\n",
    "    combined_start_end = lambda_factor * ( (start_loss + end_loss) + alpha*(start_l1 + end_l1) )\n",
    "\n",
    "    total_loss = combined_recon + kld_loss + combined_start_end\n",
    "    return total_loss, recon_loss, kld_loss, (start_loss+start_l1), (end_loss+end_l1)\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar, start_point, end_point, lambda_factor=3):\n",
    "    recon_loss = F.mse_loss(recon_x, x, reduction='mean')\n",
    "    kld_loss = -0.5*0.8 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    start_loss = F.mse_loss(recon_x[:,0,:], start_point, reduction='mean')\n",
    "    end_loss = F.mse_loss(recon_x[:,-1,:], end_point, reduction='mean')\n",
    "    extra_term = 10 * (start_loss**2 + end_loss**2)\n",
    "    total_loss = recon_loss + kld_loss + start_loss + lambda_factor*end_loss + extra_term\n",
    "    return total_loss, recon_loss, kld_loss, start_loss, end_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099fba3f-f89d-4338-949a-160ed8b057ba",
   "metadata": {},
   "source": [
    "2.4 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae530cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CVAE()\n",
    "model.train()\n",
    "optimizer = optim.Adam(model.parameters(), lr=7e-4)\n",
    "num_epochs = 300\n",
    "\n",
    "best_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    total_rl = 0\n",
    "    total_sl = 0\n",
    "    total_el = 0\n",
    "    total_kl = 0\n",
    "    for x, c, sp, ep in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        recon, mu, logvar = model(x, c, sp, ep)\n",
    "        loss, rl, kl, sl, el = loss_function(recon, x, mu, logvar, sp, ep, lambda_factor=3)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_size = x.size(0)\n",
    "        total_loss += loss.item() * batch_size\n",
    "        total_rl += rl.item() * batch_size\n",
    "        total_kl += kl.item() * batch_size\n",
    "        total_sl += sl.item() * batch_size\n",
    "        total_el += el.item() * batch_size\n",
    "    avg_loss = total_loss / len(train_dataloader.dataset)\n",
    "    avg_rl = total_rl / len(train_dataloader.dataset)\n",
    "    avg_sl = total_sl / len(train_dataloader.dataset)\n",
    "    avg_el = total_el / len(train_dataloader.dataset)\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        torch.save(model.state_dict(), 'best_model_3D.pt')\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] Loss: {avg_loss:.4f}, Recon:{avg_rl:.4f}, Start:{avg_sl:.4f}, End:{avg_el:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee734ef-4f95-48d6-8e17-40cc35941848",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "2.5 validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0236d671",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(2024)\n",
    "val_demos_task0, val_starts0, val_ends0, val_ids0 = generate_val_trajectories(num_demos=10, num_points=500, noise_std=noise_std, task_id=0)\n",
    "val_demos_task1, val_starts1, val_ends1, val_ids1 = generate_val_trajectories(num_demos=10, num_points=500, noise_std=noise_std, task_id=1)\n",
    "\n",
    "val_demonstrations = val_demos_task0 + val_demos_task1\n",
    "val_condition_ids = val_ids0 + val_ids1\n",
    "val_starts = val_starts0 + val_starts1\n",
    "val_ends = val_ends0 + val_ends1\n",
    "\n",
    "val_dataset = TrajectoryDataset(val_demonstrations, val_condition_ids, val_starts, val_ends)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "val_total_loss = 0\n",
    "val_total_rl = 0\n",
    "val_total_kl = 0\n",
    "val_total_sl = 0\n",
    "val_total_el = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_val, c_val, sp_val, ep_val in val_dataloader:\n",
    "        recon_val, mu_val, logvar_val = model(x_val, c_val, sp_val, ep_val)\n",
    "        v_loss, v_rl, v_kl, v_sl, v_el = loss_function(recon_val, x_val, mu_val, logvar_val, sp_val, ep_val, lambda_factor=2)\n",
    "        \n",
    "        batch_size_val = x_val.size(0)\n",
    "        val_total_loss += v_loss.item() * batch_size_val\n",
    "        val_total_rl += v_rl.item() * batch_size_val\n",
    "        val_total_kl += v_kl.item() * batch_size_val\n",
    "        val_total_sl += v_sl.item() * batch_size_val\n",
    "        val_total_el += v_el.item() * batch_size_val\n",
    "\n",
    "val_size = len(val_dataset)\n",
    "avg_val_loss = val_total_loss / val_size\n",
    "avg_val_rl = val_total_rl / val_size\n",
    "avg_val_kl = val_total_kl / val_size\n",
    "avg_val_sl = val_total_sl / val_size\n",
    "avg_val_el = val_total_el / val_size\n",
    "\n",
    "print(f\"Validation: Loss={avg_val_loss:.4f}, Recon={avg_val_rl:.4f}, Start={avg_val_sl:.4f}, End={avg_val_el:.4f}, KL={avg_val_kl:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d00838-ed33-4795-854a-4ce213a7d7ad",
   "metadata": {},
   "source": [
    "2.6 visuliazation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770abbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = CVAE()\n",
    "# model.load_state_dict(torch.load('best_model_3D.pt'))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_task = 1\n",
    "    start_point = np.array([1.05, 1.08, 1.02], dtype=np.float32)\n",
    "    end_point = np.array([2.00, 2.03, 2.09], dtype=np.float32)\n",
    "    start_point_tensor = torch.tensor([start_point], dtype=torch.float32)\n",
    "    end_point_tensor = torch.tensor([end_point], dtype=torch.float32)\n",
    "    test_cond = torch.tensor([test_task], dtype=torch.long)\n",
    "    z_sample = torch.randn(1, 64)\n",
    "    generated_trajectory = model.decoder(z_sample, test_cond, start_point_tensor, end_point_tensor, seq_len=500)\n",
    "\n",
    "visualize_trajectories(generated_trajectory.squeeze(0).cpu().numpy(), title=f\"Generated 3D Trajectory (Task={test_task})\")\n",
    "\n",
    "gen_start = generated_trajectory[:,0,:]\n",
    "gen_end = generated_trajectory[:,-1,:]\n",
    "\n",
    "error_start = torch.norm(gen_start - start_point_tensor)\n",
    "error_end = torch.norm(gen_end - end_point_tensor)\n",
    "\n",
    "print(f\"now: {start_point}, goal: {gen_start.squeeze(0).cpu().numpy()}, err: {error_start.item():.4f}\")\n",
    "print(f\"start: {end_point}, end: {gen_end.squeeze(0).cpu().numpy()}, err: {error_end.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
